{
    "credentials": {
        "pinecone": {
            "name": "Pinecone API",
            "type": "pineconeApi",
            "data": {
                "apiKey": "YOUR_PINECONE_API_KEY_HERE",
                "environment": "aped-4627-b74a"
            },
            "notes": "Get API key from https://app.pinecone.io → API Keys"
        },
        "openai": {
            "name": "OpenAI API",
            "type": "openAiApi",
            "data": {
                "apiKey": "YOUR_OPENAI_API_KEY_HERE"
            },
            "notes": "Get API key from https://platform.openai.com/api-keys"
        }
    },
    "required_models": {
        "openai_models": [
            {
                "name": "gpt-4o-mini",
                "purpose": "Chat completions and reasoning",
                "install": "Available via API"
            },
            {
                "name": "text-embedding-3-small",
                "purpose": "Vector embeddings",
                "install": "Available via API"
            }
        ]
    },
    "pinecone_configuration": {
        "index_name": "manufacturing-rag",
        "dimension": 1536,
        "metric": "cosine",
        "host": "https://manufacturing-rag-96ag0kp.svc.aped-4627-b74a.pinecone.io"
    },
    "n8n_configuration": {
        "version": "1.0+",
        "installation": "npx n8n or Docker",
        "access_url": "http://localhost:5678"
    },
    "setup_steps": [
        "1. Obtain an OpenAI API Key from platform.openai.com",
        "2. Obtain a Pinecone API Key from app.pinecone.io",
        "3. Start n8n: npx n8n",
        "4. In n8n UI → Settings → Credentials → Add New:",
        "   - Create 'OpenAI API' credential with your key",
        "   - Create 'Pinecone API' credential with your key",
        "5. Import all workflows from n8n_workflows/",
        "6. Run 04_Data_Ingestion workflow to populate vectors",
        "7. Test with: curl -X POST http://localhost:5678/webhook/chat -d '{\"query\": \"What was MC001 OEE yesterday?\"}'"
    ]
}